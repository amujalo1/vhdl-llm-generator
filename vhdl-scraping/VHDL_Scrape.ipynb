{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               input  \\\n",
            "0  # VHDL Analysis for 'lxp32_alu.vhd'\\n\\n## File...   \n",
            "\n",
            "                                              output  \n",
            "0  ----------------------------------------------...  \n",
            "\n",
            "Total VHDL files processed: 20\n",
            "Average description length: 2059.50 characters\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Repository information\n",
        "repo_owner = \"lxp32\"\n",
        "repo_name = \"lxp32-cpu\"\n",
        "branch = \"develop\"\n",
        "path = \"rtl\"\n",
        "\n",
        "# GitHub API URL to get contents of the directory\n",
        "api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{path}?ref={branch}\"\n",
        "\n",
        "# Send request to GitHub API\n",
        "response = requests.get(api_url)\n",
        "contents = response.json()\n",
        "\n",
        "# Filter for .vhd files\n",
        "vhd_files = [item for item in contents if item['name'].endswith('.vhd')]\n",
        "\n",
        "# Initialize list to store file content\n",
        "files_data = []\n",
        "\n",
        "def extract_comments(code):\n",
        "    \"\"\"Extract comments from VHDL code.\"\"\"\n",
        "    # Extract single line comments\n",
        "    single_line_comments = re.findall(r'--(.+?)(?:\\n|$)', code)\n",
        "    \n",
        "    # Extract block comments\n",
        "    block_comments = re.findall(r'/\\*(.*?)\\*/', code, re.DOTALL)\n",
        "    \n",
        "    all_comments = single_line_comments + block_comments\n",
        "    return [comment.strip() for comment in all_comments if comment.strip()]\n",
        "\n",
        "def extract_between(text, start_marker, end_marker):\n",
        "    \"\"\"Extract text between two markers, inclusive of the markers.\"\"\"\n",
        "    start_idx = text.lower().find(start_marker.lower())\n",
        "    if start_idx == -1:\n",
        "        return None\n",
        "    \n",
        "    end_idx = text.lower().find(end_marker.lower(), start_idx)\n",
        "    if end_idx == -1:\n",
        "        return None\n",
        "    \n",
        "    return text[start_idx:end_idx + len(end_marker)]\n",
        "\n",
        "def extract_section(code, start_pattern, end_pattern=';'):\n",
        "    \"\"\"Extract a section of code between patterns.\"\"\"\n",
        "    start_match = re.search(start_pattern, code, re.IGNORECASE)\n",
        "    if not start_match:\n",
        "        return None\n",
        "    \n",
        "    start_idx = start_match.end()\n",
        "    # Find the end pattern after the start match\n",
        "    code_after_start = code[start_idx:]\n",
        "    \n",
        "    # For more complex end patterns (like \"end entity\" or \"end process\")\n",
        "    if ' ' in end_pattern:\n",
        "        end_match = re.search(end_pattern, code_after_start, re.IGNORECASE)\n",
        "        if not end_match:\n",
        "            return None\n",
        "        end_idx = end_match.start()\n",
        "    else:\n",
        "        # For simple end patterns like semicolons\n",
        "        bracket_count = 0\n",
        "        end_idx = -1\n",
        "        for i, char in enumerate(code_after_start):\n",
        "            if char == '(':\n",
        "                bracket_count += 1\n",
        "            elif char == ')':\n",
        "                bracket_count -= 1\n",
        "            elif char == end_pattern and bracket_count <= 0:\n",
        "                end_idx = i\n",
        "                break\n",
        "        \n",
        "        if end_idx == -1:\n",
        "            return None\n",
        "    \n",
        "    return code_after_start[:end_idx].strip()\n",
        "\n",
        "def extract_architecture_body(code):\n",
        "    \"\"\"Extract the architecture body between 'begin' and 'end architecture'.\"\"\"\n",
        "    arch_start = code.lower().find(\"architecture \")\n",
        "    if arch_start == -1:\n",
        "        return None\n",
        "    \n",
        "    begin_idx = code.lower().find(\" begin\", arch_start)\n",
        "    if begin_idx == -1:\n",
        "        return None\n",
        "    \n",
        "    end_arch = re.search(r'end\\s+architecture|end\\s+\\w+', code[begin_idx:].lower())\n",
        "    if not end_arch:\n",
        "        return None\n",
        "    \n",
        "    end_idx = begin_idx + end_arch.start()\n",
        "    return code[begin_idx:end_idx].strip()\n",
        "\n",
        "def extract_concurrent_statements(code):\n",
        "    \"\"\"Extract concurrent signal assignments.\"\"\"\n",
        "    # This is simplified and may not catch all concurrent statements\n",
        "    arch_body = extract_architecture_body(code)\n",
        "    if not arch_body:\n",
        "        return []\n",
        "    \n",
        "    # Split by semicolons and filter out process blocks\n",
        "    lines = arch_body.split(';')\n",
        "    concurrent_stmts = []\n",
        "    \n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line and 'process' not in line.lower() and 'begin' not in line.lower():\n",
        "            concurrent_stmts.append(line)\n",
        "    \n",
        "    return concurrent_stmts\n",
        "\n",
        "def extract_entity_ports(code):\n",
        "    \"\"\"Extract and categorize entity ports as inputs, outputs, or bidirectional.\"\"\"\n",
        "    port_section = extract_section(code, r'port\\s*\\(', r'\\);')\n",
        "    if not port_section:\n",
        "        return [], [], []\n",
        "    \n",
        "    # Split into individual port declarations\n",
        "    port_lines = [p.strip() for p in port_section.split(';')]\n",
        "    \n",
        "    inputs = []\n",
        "    outputs = []\n",
        "    bidirectional = []\n",
        "    \n",
        "    for port in port_lines:\n",
        "        if not port:\n",
        "            continue\n",
        "            \n",
        "        # Handle multiple signals on the same line\n",
        "        parts = port.split(':')\n",
        "        if len(parts) < 2:\n",
        "            continue\n",
        "            \n",
        "        signal_names = [s.strip() for s in parts[0].split(',')]\n",
        "        direction = parts[1].lower()\n",
        "        \n",
        "        for name in signal_names:\n",
        "            if 'in' in direction and 'out' not in direction:\n",
        "                inputs.append(f\"{name}: {direction}\")\n",
        "            elif 'out' in direction and 'in' not in direction:\n",
        "                outputs.append(f\"{name}: {direction}\")\n",
        "            elif 'inout' in direction or ('in' in direction and 'out' in direction):\n",
        "                bidirectional.append(f\"{name}: {direction}\")\n",
        "    \n",
        "    return inputs, outputs, bidirectional\n",
        "\n",
        "def extract_generic_parameters(code):\n",
        "    \"\"\"Extract generic parameters if they exist.\"\"\"\n",
        "    generic_section = extract_section(code, r'generic\\s*\\(', r'\\);')\n",
        "    if not generic_section:\n",
        "        return []\n",
        "    \n",
        "    # Split into individual generic declarations\n",
        "    generic_lines = [g.strip() for g in generic_section.split(';')]\n",
        "    generics = []\n",
        "    \n",
        "    for generic in generic_lines:\n",
        "        if generic:\n",
        "            generics.append(generic)\n",
        "    \n",
        "    return generics\n",
        "\n",
        "def extract_processes(code):\n",
        "    \"\"\"Extract process blocks and their sensitivity lists.\"\"\"\n",
        "    processes = []\n",
        "    \n",
        "    # Pattern for process with sensitivity list\n",
        "    pattern1 = re.compile(r'(\\w+\\s*:\\s*)?process\\s*\\(([^)]*)\\)(.*?)end\\s+process', re.DOTALL | re.IGNORECASE)\n",
        "    \n",
        "    # Pattern for process without sensitivity list\n",
        "    pattern2 = re.compile(r'(\\w+\\s*:\\s*)?process\\s*(?!\\()(.+?)end\\s+process', re.DOTALL | re.IGNORECASE)\n",
        "    \n",
        "    # Find processes with sensitivity lists\n",
        "    for match in pattern1.finditer(code):\n",
        "        process_label = match.group(1).strip(':').strip() if match.group(1) else \"Unnamed process\"\n",
        "        sensitivity_list = match.group(2).strip()\n",
        "        process_body = match.group(3).strip()\n",
        "        \n",
        "        # Extract wait statements if they exist\n",
        "        wait_statements = re.findall(r'wait\\s+([^;]+);', process_body, re.IGNORECASE)\n",
        "        \n",
        "        # Check for clock-related logic\n",
        "        is_clocked = bool(re.search(r'rising_edge|falling_edge|clk\\s*\\'event', process_body, re.IGNORECASE))\n",
        "        \n",
        "        # Check for reset logic\n",
        "        has_reset = bool(re.search(r'reset|rst', process_body, re.IGNORECASE))\n",
        "        \n",
        "        process_info = {\n",
        "            \"label\": process_label,\n",
        "            \"sensitivity_list\": sensitivity_list,\n",
        "            \"body\": process_body,\n",
        "            \"wait_statements\": wait_statements,\n",
        "            \"is_clocked\": is_clocked,\n",
        "            \"has_reset\": has_reset\n",
        "        }\n",
        "        processes.append(process_info)\n",
        "    \n",
        "    # Find processes without sensitivity lists\n",
        "    for match in pattern2.finditer(code):\n",
        "        process_label = match.group(1).strip(':').strip() if match.group(1) else \"Unnamed process\"\n",
        "        process_body = match.group(2).strip()\n",
        "        \n",
        "        # Extract wait statements if they exist\n",
        "        wait_statements = re.findall(r'wait\\s+([^;]+);', process_body, re.IGNORECASE)\n",
        "        \n",
        "        # Check for clock-related logic\n",
        "        is_clocked = bool(re.search(r'rising_edge|falling_edge|clk\\s*\\'event', process_body, re.IGNORECASE))\n",
        "        \n",
        "        # Check for reset logic\n",
        "        has_reset = bool(re.search(r'reset|rst', process_body, re.IGNORECASE))\n",
        "        \n",
        "        process_info = {\n",
        "            \"label\": process_label,\n",
        "            \"sensitivity_list\": \"None (uses wait statements)\",\n",
        "            \"body\": process_body,\n",
        "            \"wait_statements\": wait_statements,\n",
        "            \"is_clocked\": is_clocked,\n",
        "            \"has_reset\": has_reset\n",
        "        }\n",
        "        processes.append(process_info)\n",
        "    \n",
        "    return processes\n",
        "\n",
        "def extract_signals(code):\n",
        "    \"\"\"Extract signal declarations and their types.\"\"\"\n",
        "    signal_pattern = re.compile(r'signal\\s+([^:]+):\\s*([^;]+);', re.IGNORECASE)\n",
        "    signals = []\n",
        "    \n",
        "    for match in signal_pattern.finditer(code):\n",
        "        signal_names = match.group(1).strip()\n",
        "        signal_type = match.group(2).strip()\n",
        "        \n",
        "        # Handle multiple signals on the same line\n",
        "        for name in [n.strip() for n in signal_names.split(',')]:\n",
        "            signals.append({\"name\": name, \"type\": signal_type})\n",
        "    \n",
        "    return signals\n",
        "\n",
        "def extract_component_declarations(code):\n",
        "    \"\"\"Extract component declarations.\"\"\"\n",
        "    component_pattern = re.compile(r'component\\s+(\\w+)(.+?)end\\s+component', re.DOTALL | re.IGNORECASE)\n",
        "    components = []\n",
        "    \n",
        "    for match in component_pattern.finditer(code):\n",
        "        component_name = match.group(1).strip()\n",
        "        component_body = match.group(2).strip()\n",
        "        components.append({\"name\": component_name, \"body\": component_body})\n",
        "    \n",
        "    return components\n",
        "\n",
        "def extract_component_instantiations(code):\n",
        "    \"\"\"Extract component instantiations.\"\"\"\n",
        "    # This is a simplified pattern that might need refinement\n",
        "    inst_pattern = re.compile(r'(\\w+)\\s*:\\s*(?:entity\\s+\\w+\\.)?(\\w+)(?:\\s+\\w+\\s+\\w+)?(?:\\s+generic\\s+map\\s*\\(([^)]+)\\))?(?:\\s+port\\s+map\\s*\\(([^)]+)\\))', re.IGNORECASE)\n",
        "    instantiations = []\n",
        "    \n",
        "    for match in inst_pattern.finditer(code):\n",
        "        instance_name = match.group(1).strip()\n",
        "        component_name = match.group(2).strip()\n",
        "        generic_map = match.group(3).strip() if match.group(3) else None\n",
        "        port_map = match.group(4).strip() if match.group(4) else None\n",
        "        \n",
        "        instantiations.append({\n",
        "            \"instance\": instance_name,\n",
        "            \"component\": component_name,\n",
        "            \"generic_map\": generic_map,\n",
        "            \"port_map\": port_map\n",
        "        })\n",
        "    \n",
        "    return instantiations\n",
        "\n",
        "def identify_fsm(code):\n",
        "    \"\"\"Identify if the VHDL code likely implements a Finite State Machine.\"\"\"\n",
        "    # Look for state variable declarations\n",
        "    state_vars = re.findall(r'type\\s+\\w+\\s+is\\s*\\(([^)]+)\\)', code, re.IGNORECASE)\n",
        "    state_signals = re.findall(r'signal\\s+\\w+(?:\\s*,\\s*\\w+)*\\s*:\\s*\\w+_state', code, re.IGNORECASE)\n",
        "    \n",
        "    # Look for case statements often used in FSMs\n",
        "    case_statements = re.findall(r'case\\s+(\\w+)\\s+is', code, re.IGNORECASE)\n",
        "    \n",
        "    # Look for state transitions\n",
        "    next_state_assignments = re.findall(r'next_state|state\\s*<=', code, re.IGNORECASE)\n",
        "    \n",
        "    # If we find evidence of states and transitions, it's likely an FSM\n",
        "    return bool(state_vars or state_signals) and (case_statements or next_state_assignments)\n",
        "\n",
        "def generate_vhdl_description(filename, code):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive description of VHDL code that would help an LLM understand its functionality.\n",
        "    \"\"\"\n",
        "    description = f\"# VHDL Analysis for '{filename}'\\n\\n\"\n",
        "    \n",
        "    # Extract comments to understand the designer's intent\n",
        "    comments = extract_comments(code)\n",
        "    if comments:\n",
        "        description += \"## File Comments\\n\"\n",
        "        for comment in comments[:10]:  # Limit to first 10 comments to avoid overwhelming\n",
        "            description += f\"- {comment}\\n\"\n",
        "        if len(comments) > 10:\n",
        "            description += f\"- Plus {len(comments) - 10} more comments\\n\"\n",
        "        description += \"\\n\"\n",
        "    \n",
        "    # Extract libraries and packages\n",
        "    libraries = re.findall(r'library\\s+(\\w+);', code, re.IGNORECASE)\n",
        "    uses = re.findall(r'use\\s+([^;]+);', code, re.IGNORECASE)\n",
        "    \n",
        "    if libraries or uses:\n",
        "        description += \"## Libraries and Packages\\n\"\n",
        "        for lib in libraries:\n",
        "            description += f\"- Library: {lib}\\n\"\n",
        "        for use in uses:\n",
        "            description += f\"- Use: {use}\\n\"\n",
        "        description += \"\\n\"\n",
        "    \n",
        "    # Extract entity information\n",
        "    entity_block = extract_between(code, \"entity\", \"end entity\")\n",
        "    if entity_block:\n",
        "        entity_name_match = re.search(r'entity\\s+(\\w+)\\s+is', entity_block, re.IGNORECASE)\n",
        "        if entity_name_match:\n",
        "            entity_name = entity_name_match.group(1)\n",
        "            description += f\"## Entity: {entity_name}\\n\\n\"\n",
        "            \n",
        "            # Extract generic parameters\n",
        "            generics = extract_generic_parameters(entity_block)\n",
        "            if generics:\n",
        "                description += \"### Generic Parameters\\n\"\n",
        "                for generic in generics:\n",
        "                    description += f\"- {generic}\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            # Extract and categorize ports\n",
        "            inputs, outputs, bidirectional = extract_entity_ports(entity_block)\n",
        "            \n",
        "            if inputs:\n",
        "                description += \"### Input Ports\\n\"\n",
        "                for port in inputs:\n",
        "                    description += f\"- {port}\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            if outputs:\n",
        "                description += \"### Output Ports\\n\"\n",
        "                for port in outputs:\n",
        "                    description += f\"- {port}\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            if bidirectional:\n",
        "                description += \"### Bidirectional Ports\\n\"\n",
        "                for port in bidirectional:\n",
        "                    description += f\"- {port}\\n\"\n",
        "                description += \"\\n\"\n",
        "    \n",
        "    # Extract architecture information\n",
        "    arch_block = extract_between(code, \"architecture\", \"end architecture\")\n",
        "    if not arch_block:\n",
        "        arch_block = extract_between(code, \"architecture\", \"end\")  # Some VHDL uses shortened \"end\"\n",
        "        \n",
        "    if arch_block:\n",
        "        arch_name_match = re.search(r'architecture\\s+(\\w+)\\s+of\\s+(\\w+)', arch_block, re.IGNORECASE)\n",
        "        if arch_name_match:\n",
        "            arch_name = arch_name_match.group(1)\n",
        "            arch_of = arch_name_match.group(2)\n",
        "            description += f\"## Architecture: {arch_name} of {arch_of}\\n\\n\"\n",
        "            \n",
        "            # Extract signals\n",
        "            signals = extract_signals(arch_block)\n",
        "            if signals:\n",
        "                description += \"### Signals\\n\"\n",
        "                for signal in signals:\n",
        "                    description += f\"- {signal['name']}: {signal['type']}\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            # Extract component declarations\n",
        "            components = extract_component_declarations(arch_block)\n",
        "            if components:\n",
        "                description += \"### Component Declarations\\n\"\n",
        "                for component in components:\n",
        "                    description += f\"- {component['name']}\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            # Extract component instantiations\n",
        "            instantiations = extract_component_instantiations(arch_block)\n",
        "            if instantiations:\n",
        "                description += \"### Component Instantiations\\n\"\n",
        "                for inst in instantiations:\n",
        "                    description += f\"- Instance '{inst['instance']}' of component '{inst['component']}'\\n\"\n",
        "                description += \"\\n\"\n",
        "            \n",
        "            # Extract processes\n",
        "            processes = extract_processes(arch_block)\n",
        "            if processes:\n",
        "                description += \"### Processes\\n\"\n",
        "                for process in processes:\n",
        "                    clock_info = \" (Clocked)\" if process[\"is_clocked\"] else \"\"\n",
        "                    reset_info = \" (Has Reset)\" if process[\"has_reset\"] else \"\"\n",
        "                    description += f\"- Process '{process['label']}'{clock_info}{reset_info} with sensitivity list: {process['sensitivity_list']}\\n\"\n",
        "                    \n",
        "                    # Add brief description of what the process does\n",
        "                    if \"rising_edge\" in process[\"body\"] and \"reset\" in process[\"body\"].lower():\n",
        "                        description += \"  - Implements synchronous logic with reset\\n\"\n",
        "                    elif \"rising_edge\" in process[\"body\"]:\n",
        "                        description += \"  - Implements synchronous logic\\n\"\n",
        "                    elif \"case\" in process[\"body\"].lower():\n",
        "                        description += \"  - Implements case-based selection logic\\n\"\n",
        "                    elif \"if\" in process[\"body\"].lower():\n",
        "                        description += \"  - Implements conditional logic\\n\"\n",
        "                        \n",
        "                    if process[\"wait_statements\"]:\n",
        "                        description += f\"  - Contains wait statements: {', '.join(process['wait_statements'])}\\n\"\n",
        "                \n",
        "                description += \"\\n\"\n",
        "            \n",
        "            # Extract concurrent statements (outside processes)\n",
        "            concurrent_stmts = extract_concurrent_statements(arch_block)\n",
        "            if concurrent_stmts:\n",
        "                description += \"### Concurrent Statements\\n\"\n",
        "                for stmt in concurrent_stmts[:5]:  # Limit to 5 for brevity\n",
        "                    description += f\"- {stmt}\\n\"\n",
        "                if len(concurrent_stmts) > 5:\n",
        "                    description += f\"- Plus {len(concurrent_stmts) - 5} more statements\\n\"\n",
        "                description += \"\\n\"\n",
        "    \n",
        "    # Higher-level analysis\n",
        "    description += \"## Functional Analysis\\n\\n\"\n",
        "    \n",
        "    # Check if it's likely an FSM\n",
        "    is_fsm = identify_fsm(code)\n",
        "    if is_fsm:\n",
        "        description += \"- This appears to be a Finite State Machine implementation\\n\"\n",
        "    \n",
        "    # Clock domains\n",
        "    clock_signals = re.findall(r'\\b(\\w+clk|\\w+clock|\\bclk\\b|\\bclock\\b)\\b', code, re.IGNORECASE)\n",
        "    if clock_signals:\n",
        "        unique_clocks = set(clock_signals)\n",
        "        description += f\"- Contains {len(unique_clocks)} clock domain(s): {', '.join(unique_clocks)}\\n\"\n",
        "    \n",
        "    # Reset signals\n",
        "    reset_signals = re.findall(r'\\b(\\w*rst\\w*|\\w*reset\\w*)\\b', code, re.IGNORECASE)\n",
        "    if reset_signals:\n",
        "        unique_resets = set(reset_signals)\n",
        "        description += f\"- Uses reset signal(s): {', '.join(unique_resets)}\\n\"\n",
        "    \n",
        "    # Memory elements\n",
        "    if re.search(r'\\bram\\b|\\brom\\b|\\bmemory\\b|\\bfifo\\b', code, re.IGNORECASE):\n",
        "        description += \"- Implements memory functionality\\n\"\n",
        "    \n",
        "    # ALU/computational functions\n",
        "    if re.search(r'\\balu\\b|\\badd\\b|\\bsubtract\\b|\\bmult\\b|\\bdivide\\b|\\bcompare\\b', code, re.IGNORECASE):\n",
        "        description += \"- Implements arithmetic/computational functionality\\n\"\n",
        "    \n",
        "    # Control logic\n",
        "    if re.search(r'\\bcontrol\\b|\\bcontroller\\b|\\bfsm\\b|\\bstate\\b', code, re.IGNORECASE):\n",
        "        description += \"- Implements control logic\\n\"\n",
        "    \n",
        "    # Interface logic\n",
        "    if re.search(r'\\bi2c\\b|\\bspi\\b|\\buart\\b|\\binterface\\b|\\bbus\\b', code, re.IGNORECASE):\n",
        "        description += \"- Implements interface or communication protocol\\n\"\n",
        "    \n",
        "    # Pipeline stages\n",
        "    if re.search(r'\\bpipeline\\b|\\bstage\\b', code, re.IGNORECASE):\n",
        "        description += \"- May be part of a pipeline architecture\\n\"\n",
        "    \n",
        "    # CPU components\n",
        "    if re.search(r'\\bcpu\\b|\\bprocessor\\b|\\bdecode\\b|\\bexecute\\b|\\bfetch\\b|\\bregister file\\b', code, re.IGNORECASE):\n",
        "        description += \"- This appears to be a CPU component\\n\"\n",
        "        \n",
        "        if re.search(r'\\bdecode\\b', code, re.IGNORECASE):\n",
        "            description += \"- Implements instruction decoding functionality\\n\"\n",
        "        if re.search(r'\\bexecute\\b', code, re.IGNORECASE):\n",
        "            description += \"- Implements instruction execution functionality\\n\"\n",
        "        if re.search(r'\\bfetch\\b', code, re.IGNORECASE):\n",
        "            description += \"- Implements instruction fetching functionality\\n\"\n",
        "        if re.search(r'\\bregister file\\b|\\bregbank\\b', code, re.IGNORECASE):\n",
        "            description += \"- Implements register file/bank functionality\\n\"\n",
        "    \n",
        "    # Special functionality\n",
        "    if \"function\" in code.lower():\n",
        "        function_names = re.findall(r'function\\s+(\\w+)', code, re.IGNORECASE)\n",
        "        if function_names:\n",
        "            description += f\"- Defines custom functions: {', '.join(function_names)}\\n\"\n",
        "    \n",
        "    if \"procedure\" in code.lower():\n",
        "        procedure_names = re.findall(r'procedure\\s+(\\w+)', code, re.IGNORECASE)\n",
        "        if procedure_names:\n",
        "            description += f\"- Defines custom procedures: {', '.join(procedure_names)}\\n\"\n",
        "    \n",
        "    # Size/complexity metrics\n",
        "    line_count = len(code.split('\\n'))\n",
        "    description += f\"\\n## Code Metrics\\n\"\n",
        "    description += f\"- Line count: {line_count}\\n\"\n",
        "    description += f\"- Process count: {len(processes) if 'processes' in locals() else 'N/A'}\\n\"\n",
        "    description += f\"- Signal count: {len(signals) if 'signals' in locals() else 'N/A'}\\n\"\n",
        "    \n",
        "    # Summary\n",
        "    description += \"\\n## Summary\\n\"\n",
        "    \n",
        "    # Determine module type\n",
        "    if \"top\" in filename.lower() or \"top\" in code.lower():\n",
        "        description += \"- This appears to be a top-level module in the design.\\n\"\n",
        "    elif re.search(r'\\balu\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements arithmetic and logic operations.\\n\"\n",
        "    elif re.search(r'\\bcontroller\\b|\\bcontrol\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements control logic.\\n\"\n",
        "    elif re.search(r'\\bmemory\\b|\\bram\\b|\\brom\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements memory functionality.\\n\"\n",
        "    elif re.search(r'\\bregister\\b|\\breg\\b|\\bff\\b', code, re.IGNORECASE) and not re.search(r'\\bregister file\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements register or flip-flop functionality.\\n\"\n",
        "    elif re.search(r'\\bdecode\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements decoding functionality.\\n\"\n",
        "    elif re.search(r'\\bpipeline\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements a pipeline stage.\\n\"\n",
        "    elif re.search(r'\\bi2c\\b|\\bspi\\b|\\buart\\b', code, re.IGNORECASE):\n",
        "        description += \"- This module implements a communication interface.\\n\"\n",
        "    else:\n",
        "        description += \"- This module appears to be a general-purpose digital logic implementation.\\n\"\n",
        "    \n",
        "    # Final contextual note for LXP32 CPU\n",
        "    description += f\"\\nThis file is part of the LXP32 CPU design, which is likely a 32-bit processor implementation. The file '{filename}' plays a specific role in the overall CPU architecture.\\n\"\n",
        "    \n",
        "    return description\n",
        "\n",
        "# Fetch content for each .vhd file\n",
        "for file in vhd_files:\n",
        "    file_url = file['download_url']\n",
        "    file_response = requests.get(file_url)\n",
        "    \n",
        "    # Check if request was successful\n",
        "    if file_response.status_code == 200:\n",
        "        file_content = file_response.text\n",
        "        description = generate_vhdl_description(file['name'], file_content)\n",
        "        \n",
        "        files_data.append({\n",
        "            'input': description,\n",
        "            'output': file_content\n",
        "        })\n",
        "    else:\n",
        "        files_data.append({\n",
        "            'input': f\"Error analyzing file {file['name']}\",\n",
        "            'output': f\"Error fetching file: {file_response.status_code}\"\n",
        "        })\n",
        "    \n",
        "    # Add a small delay to avoid hitting API rate limits\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "df = pd.DataFrame(files_data)\n",
        "\n",
        "# Save to CSV file\n",
        "df.to_csv('lxp32_vhdl_files', index=False)\n",
        "\n",
        "# Display the first row of the DataFrame to see an example\n",
        "print(df.head(1))\n",
        "\n",
        "# Optionally print some statistics\n",
        "print(f\"\\nTotal VHDL files processed: {len(files_data)}\")\n",
        "print(f\"Average description length: {df['input'].str.len().mean():.2f} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnxbKXoQ5kXd",
        "outputId": "77cd81b0-6b0d-4635-de40-5d60c9e0bc94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing coprocessor.vhd...\n",
            "  Successfully processed coprocessor.vhd\n",
            "Processing dbus_monitor.vhd...\n",
            "  Successfully processed dbus_monitor.vhd\n",
            "Processing generic_dpram.vhd...\n",
            "  Successfully processed generic_dpram.vhd\n",
            "Processing ibus_adapter.vhd...\n",
            "  Successfully processed ibus_adapter.vhd\n",
            "Processing intercon.vhd...\n",
            "  Successfully processed intercon.vhd\n",
            "Processing platform.vhd...\n",
            "  Successfully processed platform.vhd\n",
            "Processing program_ram.vhd...\n",
            "  Successfully processed program_ram.vhd\n",
            "Processing scrambler.vhd...\n",
            "  Successfully processed scrambler.vhd\n",
            "Processing timer.vhd...\n",
            "  Successfully processed timer.vhd\n",
            "\n",
            "Done! Results saved to vhdl_dataset_lxp32.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import csv\n",
        "from time import sleep\n",
        "\n",
        "# Konfiguracija\n",
        "GITHUB_API_URL = \"https://api.github.com/repos/lxp32/lxp32-cpu/contents/verify/lxp32/src/platform\"\n",
        "RAW_BASE_URL = \"https://raw.githubusercontent.com/lxp32/lxp32-cpu/develop/verify/lxp32/src/platform/\"\n",
        "OUTPUT_CSV = \"vhdl_dataset_lxp32.csv\"\n",
        "\n",
        "def get_vhdl_files():\n",
        "    \"\"\"Dohvata listu svih VHDL fajlova sa GitHub-a\"\"\"\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code == 200:\n",
        "        files = response.json()\n",
        "        return [file[\"name\"] for file in files if file[\"name\"].endswith(\".vhd\")]\n",
        "    else:\n",
        "        print(f\"Error fetching files: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "def clean_description(desc):\n",
        "    \"\"\"Čisti opis - uklanja copyright i dekorativne linije\"\"\"\n",
        "    lines = []\n",
        "    for line in desc.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if not line or 'copyright' in line.lower() or line.startswith('---'):\n",
        "            continue\n",
        "        if line.startswith('--'):\n",
        "            line = line[2:].strip()\n",
        "        lines.append(line)\n",
        "    return ' '.join(lines).strip()\n",
        "\n",
        "def extract_content(vhdl_content):\n",
        "    \"\"\"Izdvaja opis i kod iz VHDL sadržaja\"\"\"\n",
        "    # Pronađi početak koda (nakon komentara)\n",
        "    code_start = 0\n",
        "    comment_block = re.search(r'^-{3,}.*?-{3,}', vhdl_content, re.DOTALL)\n",
        "    if comment_block:\n",
        "        code_start = comment_block.end()\n",
        "\n",
        "    # Ekstrakcija opisa\n",
        "    description = clean_description(vhdl_content[:code_start]) if code_start > 0 else \"\"\n",
        "\n",
        "    # Ekstrakcija koda sa očuvanim formatom\n",
        "    code = vhdl_content[code_start:].strip()\n",
        "    # Ukloni linijske komentare ali zadrži nove redove\n",
        "    code = '\\n'.join([line for line in code.split('\\n') if not line.strip().startswith('--')])\n",
        "\n",
        "    return description, code\n",
        "\n",
        "def main():\n",
        "    vhdl_files = get_vhdl_files()\n",
        "\n",
        "    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
        "        writer.writerow(['input', 'output'])  # Header\n",
        "\n",
        "        for filename in vhdl_files:\n",
        "            print(f\"Processing {filename}...\")\n",
        "            raw_url = RAW_BASE_URL + filename\n",
        "            response = requests.get(raw_url)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                # Get your existing basic description\n",
        "                basic_description, original_code = extract_content(response.text)\n",
        "                \n",
        "                if not basic_description:\n",
        "                    basic_description = f\"VHDL component {filename.split('.')[0]}\"\n",
        "                \n",
        "                # Generate the comprehensive description\n",
        "                detailed_description = generate_vhdl_description(filename, response.text)\n",
        "                \n",
        "                # Combine both descriptions\n",
        "                combined_description = f\"{basic_description}\\n\\n{detailed_description}\"\n",
        "                \n",
        "                # Save the original code and combined description\n",
        "                writer.writerow([combined_description, response.text])\n",
        "                print(f\"  Successfully processed {filename}\")\n",
        "            else:\n",
        "                print(f\"  Failed to fetch {filename}\")\n",
        "\n",
        "            sleep(1)  # To avoid rate limiting\n",
        "\n",
        "    print(f\"\\nDone! Results saved to {OUTPUT_CSV}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEhNnkbA-w15",
        "outputId": "b5955f9e-8469-46b6-8bc8-9ab343f2daeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing olo_base_arb_prio.vhd...\n",
            "  Successfully processed olo_base_arb_prio.vhd\n",
            "Processing olo_base_arb_rr.vhd...\n",
            "  Successfully processed olo_base_arb_rr.vhd\n",
            "Processing olo_base_cam.vhd...\n",
            "  Successfully processed olo_base_cam.vhd\n",
            "Processing olo_base_cc_bits.vhd...\n",
            "  Successfully processed olo_base_cc_bits.vhd\n",
            "Processing olo_base_cc_handshake.vhd...\n",
            "  Successfully processed olo_base_cc_handshake.vhd\n",
            "Processing olo_base_cc_n2xn.vhd...\n",
            "  Successfully processed olo_base_cc_n2xn.vhd\n",
            "Processing olo_base_cc_pulse.vhd...\n",
            "  Successfully processed olo_base_cc_pulse.vhd\n",
            "Processing olo_base_cc_reset.vhd...\n",
            "  Successfully processed olo_base_cc_reset.vhd\n",
            "Processing olo_base_cc_simple.vhd...\n",
            "  Successfully processed olo_base_cc_simple.vhd\n",
            "Processing olo_base_cc_status.vhd...\n",
            "  Successfully processed olo_base_cc_status.vhd\n",
            "Processing olo_base_cc_xn2n.vhd...\n",
            "  Successfully processed olo_base_cc_xn2n.vhd\n",
            "Processing olo_base_crc.vhd...\n",
            "  Successfully processed olo_base_crc.vhd\n",
            "Processing olo_base_decode_firstbit.vhd...\n",
            "  Successfully processed olo_base_decode_firstbit.vhd\n",
            "Processing olo_base_delay.vhd...\n",
            "  Successfully processed olo_base_delay.vhd\n",
            "Processing olo_base_delay_cfg.vhd...\n",
            "  Successfully processed olo_base_delay_cfg.vhd\n",
            "Processing olo_base_dyn_sft.vhd...\n",
            "  Successfully processed olo_base_dyn_sft.vhd\n",
            "Processing olo_base_fifo_async.vhd...\n",
            "  Successfully processed olo_base_fifo_async.vhd\n",
            "Processing olo_base_fifo_packet.vhd...\n",
            "  Successfully processed olo_base_fifo_packet.vhd\n",
            "Processing olo_base_fifo_sync.vhd...\n",
            "  Successfully processed olo_base_fifo_sync.vhd\n",
            "Processing olo_base_flowctrl_handler.vhd...\n",
            "  Successfully processed olo_base_flowctrl_handler.vhd\n",
            "Processing olo_base_pkg_array.vhd...\n",
            "  Successfully processed olo_base_pkg_array.vhd\n",
            "Processing olo_base_pkg_attribute.vhd...\n",
            "  Successfully processed olo_base_pkg_attribute.vhd\n",
            "Processing olo_base_pkg_logic.vhd...\n",
            "  Successfully processed olo_base_pkg_logic.vhd\n",
            "Processing olo_base_pkg_math.vhd...\n",
            "  Successfully processed olo_base_pkg_math.vhd\n",
            "Processing olo_base_pkg_string.vhd...\n",
            "  Successfully processed olo_base_pkg_string.vhd\n",
            "Processing olo_base_pl_stage.vhd...\n",
            "  Successfully processed olo_base_pl_stage.vhd\n",
            "Processing olo_base_prbs.vhd...\n",
            "  Successfully processed olo_base_prbs.vhd\n",
            "Processing olo_base_ram_sdp.vhd...\n",
            "  Successfully processed olo_base_ram_sdp.vhd\n",
            "Processing olo_base_ram_sp.vhd...\n",
            "  Successfully processed olo_base_ram_sp.vhd\n",
            "Processing olo_base_ram_tdp.vhd...\n",
            "  Successfully processed olo_base_ram_tdp.vhd\n",
            "Processing olo_base_reset_gen.vhd...\n",
            "  Successfully processed olo_base_reset_gen.vhd\n",
            "Processing olo_base_strobe_div.vhd...\n",
            "  Successfully processed olo_base_strobe_div.vhd\n",
            "Processing olo_base_strobe_gen.vhd...\n",
            "  Successfully processed olo_base_strobe_gen.vhd\n",
            "Processing olo_base_tdm_mux.vhd...\n",
            "  Successfully processed olo_base_tdm_mux.vhd\n",
            "Processing olo_base_wconv_n2m.vhd...\n",
            "  Successfully processed olo_base_wconv_n2m.vhd\n",
            "Processing olo_base_wconv_n2xn.vhd...\n",
            "  Successfully processed olo_base_wconv_n2xn.vhd\n",
            "Processing olo_base_wconv_xn2n.vhd...\n",
            "  Successfully processed olo_base_wconv_xn2n.vhd\n",
            "\n",
            "Done! Results saved to open_logic_vhdl_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "import csv\n",
        "from time import sleep\n",
        "from urllib.parse import unquote\n",
        "\n",
        "# Konfiguracija\n",
        "GITHUB_API_URL = \"https://api.github.com/repos/open-logic/open-logic/contents/src/base/vhdl\"\n",
        "RAW_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/src/base/vhdl/\"\n",
        "DOCS_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/doc/base/\"\n",
        "OUTPUT_CSV = \"open_logic_vhdl_dataset.csv\"\n",
        "\n",
        "def get_vhdl_files():\n",
        "    \"\"\"Dohvata listu svih VHDL fajlova sa GitHub-a\"\"\"\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code == 200:\n",
        "        files = response.json()\n",
        "        return [file[\"name\"] for file in files if file[\"name\"].endswith(\".vhd\")]\n",
        "    else:\n",
        "        print(f\"Error fetching files: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "def extract_md_description(md_content):\n",
        "    \"\"\"Ekstrahira Description dio iz markdown fajla\"\"\"\n",
        "    # Pronađi Description sekciju\n",
        "    desc_match = re.search(\n",
        "        r'^##\\s*Description\\s*$(.*?)(?=^##\\s|\\Z)',\n",
        "        md_content,\n",
        "        re.DOTALL | re.MULTILINE | re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    if not desc_match:\n",
        "        return \"\"\n",
        "\n",
        "    description = desc_match.group(1).strip()\n",
        "\n",
        "    # Ukloni slike i specijalne markdown elemente\n",
        "    description = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', description)\n",
        "    description = re.sub(r'`.*?`', '', description)\n",
        "\n",
        "    # Očisti prazne linije i višestruke razmake\n",
        "    clean_lines = []\n",
        "    for line in description.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line and not line.startswith('#'):\n",
        "            clean_lines.append(line)\n",
        "\n",
        "    return ' '.join(clean_lines).strip()\n",
        "\n",
        "def get_description_from_docs(vhdl_filename):\n",
        "    \"\"\"Dohvata opis iz odgovarajućeg .md fajla u dokumentaciji\"\"\"\n",
        "    md_filename = vhdl_filename.replace('.vhd', '.md')\n",
        "    doc_url = DOCS_BASE_URL + md_filename\n",
        "\n",
        "    try:\n",
        "        response = requests.get(doc_url)\n",
        "        if response.status_code == 200:\n",
        "            return extract_md_description(response.text)\n",
        "    except Exception as e:\n",
        "        print(f\"  Error fetching docs: {e}\")\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def extract_vhdl_description(vhdl_content):\n",
        "    \"\"\"Izdvaja Description dio iz VHDL header-a\"\"\"\n",
        "    desc_match = re.search(\n",
        "        r'^-{3,}\\s*Description\\s*-{3,}\\s*(.*?)(?=^-{3,}|\\Z)',\n",
        "        vhdl_content,\n",
        "        re.DOTALL | re.MULTILINE\n",
        "    )\n",
        "\n",
        "    if not desc_match:\n",
        "        return \"\"\n",
        "\n",
        "    description = desc_match.group(1)\n",
        "    clean_lines = []\n",
        "    for line in description.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line.startswith('--'):\n",
        "            line = line[2:].strip()\n",
        "        if line and not line.startswith('Documentation:') and not line.startswith('Note:'):\n",
        "            clean_lines.append(line)\n",
        "\n",
        "    return ' '.join(clean_lines).strip()\n",
        "\n",
        "def extract_content(vhdl_filename, vhdl_content):\n",
        "    \"\"\"Glavna funkcija za ekstrakciju opisa i koda\"\"\"\n",
        "    # Prvo pokušaj iz VHDL header-a\n",
        "    description = extract_vhdl_description(vhdl_content)\n",
        "\n",
        "    # Ako nema dobrog opisa, pokušaj iz dokumentacije\n",
        "    if not description or len(description.split()) < 10:  # Ako je opis prekratak\n",
        "        description = get_description_from_docs(vhdl_filename)\n",
        "\n",
        "    # Ako i dalje nema opisa, koristi fallback\n",
        "    if not description:\n",
        "        description = f\"VHDL component {vhdl_filename.split('.')[0]}\"\n",
        "\n",
        "    # Ekstrakcija koda\n",
        "    code_start = 0\n",
        "    header_end = re.search(r'^-{3,}\\s*Libraries\\s*-{3,}', vhdl_content, re.MULTILINE | re.IGNORECASE)\n",
        "    if header_end:\n",
        "        code_start = header_end.end()\n",
        "\n",
        "    code = vhdl_content[code_start:].strip()\n",
        "    code = '\\n'.join([line for line in code.split('\\n') if not line.strip().startswith('--')])\n",
        "\n",
        "    return description, code\n",
        "\n",
        "def main():\n",
        "    vhdl_files = get_vhdl_files()\n",
        "\n",
        "    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
        "        writer.writerow(['input', 'output'])  # Header\n",
        "\n",
        "        for filename in vhdl_files:\n",
        "            print(f\"Processing {filename}...\")\n",
        "            raw_url = RAW_BASE_URL + filename\n",
        "            response = requests.get(raw_url)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                description, code = extract_content(filename, response.text)\n",
        "                description += f\"\\n\\n{generate_vhdl_description(filename, response.text)}\"\n",
        "                writer.writerow([description, code])\n",
        "                print(f\"  Successfully processed {filename}\")\n",
        "            else:\n",
        "                print(f\"  Failed to fetch {filename}\")\n",
        "\n",
        "            sleep(1)  # Rate limiting\n",
        "\n",
        "    print(f\"\\nDone! Results saved to {OUTPUT_CSV}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VifMeAMDzuU",
        "outputId": "a9ebc005-a7a0-49c1-ec65-d7409088c16f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing olo_intf_clk_meas.vhd...\n",
            "  Successfully processed olo_intf_clk_meas.vhd\n",
            "Processing olo_intf_debounce.vhd...\n",
            "  Successfully processed olo_intf_debounce.vhd\n",
            "Processing olo_intf_i2c_master.vhd...\n",
            "  Successfully processed olo_intf_i2c_master.vhd\n",
            "Processing olo_intf_spi_master.vhd...\n",
            "  Successfully processed olo_intf_spi_master.vhd\n",
            "Processing olo_intf_spi_slave.vhd...\n",
            "  Successfully processed olo_intf_spi_slave.vhd\n",
            "Processing olo_intf_sync.vhd...\n",
            "  Successfully processed olo_intf_sync.vhd\n",
            "Processing olo_intf_uart.vhd...\n",
            "  Successfully processed olo_intf_uart.vhd\n",
            "\n",
            "Done! Results saved to open_logic_intf_vhdl_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "GITHUB_API_URL = \"https://api.github.com/repos/open-logic/open-logic/contents/src/intf/vhdl\"\n",
        "RAW_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/src/intf/vhdl/\"\n",
        "DOCS_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/doc/intf/\"\n",
        "OUTPUT_CSV = \"open_logic_intf_vhdl_dataset.csv\"  # Novi naziv CSV fajla\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SRj3RynIqpu",
        "outputId": "41d7ceee-9989-4e0c-e396-11c167ff0467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing olo_axi_lite_slave.vhd...\n",
            "  Successfully processed olo_axi_lite_slave.vhd\n",
            "Processing olo_axi_master_full.vhd...\n",
            "  Successfully processed olo_axi_master_full.vhd\n",
            "Processing olo_axi_master_simple.vhd...\n",
            "  Successfully processed olo_axi_master_simple.vhd\n",
            "Processing olo_axi_pkg_protocol.vhd...\n",
            "  Successfully processed olo_axi_pkg_protocol.vhd\n",
            "Processing olo_axi_pl_stage.vhd...\n",
            "  Successfully processed olo_axi_pl_stage.vhd\n",
            "\n",
            "Done! Results saved to open_logic_axi_vhdl_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "GITHUB_API_URL = \"https://api.github.com/repos/open-logic/open-logic/contents/src/axi/vhdl\"\n",
        "RAW_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/src/axi/vhdl/\"\n",
        "DOCS_BASE_URL = \"https://raw.githubusercontent.com/open-logic/open-logic/main/doc/axi/\"\n",
        "OUTPUT_CSV = \"open_logic_axi_vhdl_dataset.csv\"\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Login using e.g. `huggingface-cli login` to access this dataset\n",
        "ds = load_dataset(\"rtl-llm/vhdl_github\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spremljeno u 'huggingface_ds.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_dataset = ds['train']\n",
        "first_five = train_dataset[:1000]\n",
        "\n",
        "\n",
        "rows = []\n",
        "\n",
        "for content in first_five['content']:\n",
        "    if content is None:\n",
        "        continue  # preskoči ako je None\n",
        "\n",
        "    input_lines = []\n",
        "    output_lines = []\n",
        "    in_comment_block = True\n",
        "\n",
        "    for line in content.splitlines():\n",
        "        stripped = line.strip()\n",
        "        if stripped.startswith(\"--\"):\n",
        "            if not any(keyword in stripped for keyword in [\"Copyright\", \"Author\", \"Contact\"]):\n",
        "                clean_line = stripped[2:].strip(\"- \").strip()\n",
        "                if clean_line:\n",
        "                    input_lines.append(clean_line)\n",
        "        else:\n",
        "            in_comment_block = False\n",
        "            output_lines.append(stripped)\n",
        "\n",
        "    input_text = \"\\n\".join(input_lines).strip()\n",
        "    output_text = \"\\n\".join(output_lines).strip()\n",
        "\n",
        "    if input_text or output_text:\n",
        "        rows.append({\"input\": input_text, \"output\": output_text})\n",
        "\n",
        "# Snimi u CSV\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(\"huggingface_ds.csv\", index=False)\n",
        "\n",
        "print(\"Spremljeno u 'huggingface_ds.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Učitavanje: open_logic_intf_vhdl_dataset.csv\n",
            "Učitano 7 zapisa iz open_logic_intf_vhdl_dataset.csv\n",
            "Učitavanje: open_logic_vhdl_dataset.csv\n",
            "Učitano 37 zapisa iz open_logic_vhdl_dataset.csv\n",
            "Učitavanje: open_logic_axi_vhdl_dataset.csv\n",
            "Učitano 5 zapisa iz open_logic_axi_vhdl_dataset.csv\n",
            "Učitavanje: vhdl_dataset_lxp32.csv\n",
            "Učitano 9 zapisa iz vhdl_dataset_lxp32.csv\n",
            "Učitavanje: lxp32_vhdl_files.csv\n",
            "Učitano 20 zapisa iz lxp32_vhdl_files.csv\n",
            "\n",
            "Uspešno spojeno 5 dataseta.\n",
            "Ukupno zapisa: 78\n",
            "Konačni broj zapisa: 78\n",
            "Rezultat sačuvan u: vhdl_etf.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def merge_datasets(file_list, output_filename=\"vhdl_etf.csv\"):\n",
        "    \"\"\"\n",
        "    Spaja više CSV fajlova sa VHDL podacima u jedan dataset\n",
        "    \n",
        "    Parameters:\n",
        "        file_list (list): Lista putanja do CSV fajlova\n",
        "        output_filename (str): Ime izlaznog fajla\n",
        "    \"\"\"\n",
        "    # Lista za čuvanje svih dataframe-ova\n",
        "    dataframes = []\n",
        "    \n",
        "    # Učitavanje svakog dataseta\n",
        "    for file_path in file_list:\n",
        "        try:\n",
        "            print(f\"Učitavanje: {file_path}\")\n",
        "            df = pd.read_csv(file_path, quotechar='\"', escapechar='\\\\')\n",
        "            print(f\"Učitano {len(df)} zapisa iz {file_path}\")\n",
        "            dataframes.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Greška pri učitavanju {file_path}: {e}\")\n",
        "    \n",
        "    # Spajanje svih dataframe-ova\n",
        "    if dataframes:\n",
        "        merged_df = pd.concat(dataframes, ignore_index=True)\n",
        "        \n",
        "        # Uklanjanje duplikata ako postoje\n",
        "        before_dedup = len(merged_df)\n",
        "        merged_df = merged_df.drop_duplicates()\n",
        "        after_dedup = len(merged_df)\n",
        "        \n",
        "        # Snimanje spojenog dataseta\n",
        "        merged_df.to_csv(output_filename, index=False, quotechar='\"', escapechar='\\\\')\n",
        "        \n",
        "        print(f\"\\nUspešno spojeno {len(dataframes)} dataseta.\")\n",
        "        print(f\"Ukupno zapisa: {before_dedup}\")\n",
        "        if before_dedup > after_dedup:\n",
        "            print(f\"Uklonjeno duplikata: {before_dedup - after_dedup}\")\n",
        "        print(f\"Konačni broj zapisa: {after_dedup}\")\n",
        "        print(f\"Rezultat sačuvan u: {output_filename}\")\n",
        "        \n",
        "        return merged_df\n",
        "    else:\n",
        "        print(\"Nema validnih dataseta za spajanje.\")\n",
        "        return None\n",
        "\n",
        "# Glavni deo koda\n",
        "if __name__ == \"__main__\":\n",
        "    # Lista dataseta koje treba spojiti\n",
        "    datasets = [\n",
        "        \"open_logic_intf_vhdl_dataset.csv\",\n",
        "        \"open_logic_vhdl_dataset.csv\",\n",
        "        \"open_logic_axi_vhdl_dataset.csv\",\n",
        "        \"vhdl_dataset_lxp32.csv\",\n",
        "        \"lxp32_vhdl_files.csv\",\n",
        "    ]\n",
        "    \n",
        "    # Provera da li fajlovi postoje\n",
        "    existing_files = []\n",
        "    for ds in datasets:\n",
        "        if os.path.exists(ds):\n",
        "            existing_files.append(ds)\n",
        "        else:\n",
        "            print(f\"Upozorenje: Fajl {ds} nije pronađen.\")\n",
        "    \n",
        "    if existing_files:\n",
        "        # Spojite datasete\n",
        "        merged_data = merge_datasets(existing_files)\n",
        "    else:\n",
        "        print(\"Nijedan od navedenih fajlova nije pronađen.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
